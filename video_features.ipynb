{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract features from video per frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract features function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import cv2\n",
    "\n",
    "import util\n",
    "\n",
    "COCO_BODY_PARTS = ['nose', 'neck',\n",
    "                   'right_shoulder', ' right_elbow', 'right_wrist',\n",
    "                   'left_shoulder', 'left_elbow', 'left_wrist',\n",
    "                   'right_hip', 'right_knee', 'right_ankle',\n",
    "                   'left_hip', 'left_knee', 'left_ankle',\n",
    "                   'right_eye', 'left_eye', 'right_ear', 'left_ear', 'background'\n",
    "                   ]\n",
    "\n",
    "\n",
    "def extract_parts(input_image, params, model, model_params):\n",
    "    multiplier = [x * model_params['boxsize'] / input_image.shape[0] for x in params['scale_search']]\n",
    "\n",
    "    # Body parts location heatmap, one per part (19)\n",
    "    heatmap_avg = np.zeros((input_image.shape[0], input_image.shape[1], 19))\n",
    "    # Part affinities, one per limb (38)\n",
    "    paf_avg = np.zeros((input_image.shape[0], input_image.shape[1], 38))\n",
    "\n",
    "    for scale in multiplier:\n",
    "        tic = time.time()\n",
    "        image_to_test = cv2.resize(input_image, (0, 0), fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)\n",
    "        image_to_test_padded, pad = util.pad_right_down_corner(image_to_test, model_params['stride'],\n",
    "                                                               model_params['padValue'])\n",
    "        \n",
    "        # required shape (1, width, height, channels)\n",
    "        input_img = np.transpose(np.float32(image_to_test_padded[:, :, :, np.newaxis]), (3, 0, 1, 2))\n",
    "        \n",
    "        toc = time.time()\n",
    "        print('image rescaling time is %.5f' % (toc - tic))\n",
    "        \n",
    "        # model\n",
    "        tic = time.time()\n",
    "        output_blobs = model.predict(input_img)\n",
    "        toc = time.time()\n",
    "        print('cnn model time is %.5f' % (toc - tic))\n",
    "        \n",
    "        tic = time.time()\n",
    "        # extract outputs, resize, and remove padding\n",
    "        heatmap = np.squeeze(output_blobs[1])  # output 1 is heatmaps\n",
    "        heatmap = cv2.resize(heatmap, (0, 0), fx=model_params['stride'], fy=model_params['stride'],\n",
    "                             interpolation=cv2.INTER_CUBIC)\n",
    "        heatmap = heatmap[:image_to_test_padded.shape[0] - pad[2], :image_to_test_padded.shape[1] - pad[3], :]\n",
    "        heatmap = cv2.resize(heatmap, (input_image.shape[1], input_image.shape[0]), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        paf = np.squeeze(output_blobs[0])  # output 0 is PAFs\n",
    "        paf = cv2.resize(paf, (0, 0), fx=model_params['stride'], fy=model_params['stride'],\n",
    "                         interpolation=cv2.INTER_CUBIC)\n",
    "        paf = paf[:image_to_test_padded.shape[0] - pad[2], :image_to_test_padded.shape[1] - pad[3], :]\n",
    "        paf = cv2.resize(paf, (input_image.shape[1], input_image.shape[0]), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        heatmap_avg = heatmap_avg + heatmap / len(multiplier)\n",
    "        paf_avg = paf_avg + paf / len(multiplier)\n",
    "\n",
    "    all_peaks = []\n",
    "    peak_counter = 0\n",
    "\n",
    "    for part in range(18):\n",
    "        hmap_ori = heatmap_avg[:, :, part]\n",
    "        hmap = gaussian_filter(hmap_ori, sigma=3)\n",
    "\n",
    "        # Find the pixel that has maximum value compared to those around it\n",
    "        hmap_left = np.zeros(hmap.shape)\n",
    "        hmap_left[1:, :] = hmap[:-1, :]\n",
    "        hmap_right = np.zeros(hmap.shape)\n",
    "        hmap_right[:-1, :] = hmap[1:, :]\n",
    "        hmap_up = np.zeros(hmap.shape)\n",
    "        hmap_up[:, 1:] = hmap[:, :-1]\n",
    "        hmap_down = np.zeros(hmap.shape)\n",
    "        hmap_down[:, :-1] = hmap[:, 1:]\n",
    "\n",
    "        # reduce needed because there are > 2 arguments\n",
    "        peaks_binary = np.logical_and.reduce(\n",
    "            (hmap >= hmap_left, hmap >= hmap_right, hmap >= hmap_up, hmap >= hmap_down, hmap > params['thre1']))\n",
    "        peaks = list(zip(np.nonzero(peaks_binary)[1], np.nonzero(peaks_binary)[0]))  # note reverse\n",
    "        peaks_with_score = [x + (hmap_ori[x[1], x[0]],) for x in peaks]  # add a third element to tuple with score\n",
    "        idx = range(peak_counter, peak_counter + len(peaks))\n",
    "        peaks_with_score_and_id = [peaks_with_score[i] + (idx[i],) for i in range(len(idx))]\n",
    "\n",
    "        all_peaks.append(peaks_with_score_and_id)\n",
    "        peak_counter += len(peaks)\n",
    "\n",
    "    connection_all = []\n",
    "    special_k = []\n",
    "    mid_num = 10\n",
    "\n",
    "    for k in range(len(util.hmapIdx)):\n",
    "        score_mid = paf_avg[:, :, [x - 19 for x in util.hmapIdx[k]]]\n",
    "        cand_a = all_peaks[util.limbSeq[k][0] - 1]\n",
    "        cand_b = all_peaks[util.limbSeq[k][1] - 1]\n",
    "        n_a = len(cand_a)\n",
    "        n_b = len(cand_b)\n",
    "        # index_a, index_b = util.limbSeq[k]\n",
    "        if n_a != 0 and n_b != 0:\n",
    "            connection_candidate = []\n",
    "            for i in range(n_a):\n",
    "                for j in range(n_b):\n",
    "                    vec = np.subtract(cand_b[j][:2], cand_a[i][:2])\n",
    "                    norm = math.sqrt(vec[0] * vec[0] + vec[1] * vec[1])\n",
    "                    # failure case when 2 body parts overlaps\n",
    "                    if norm == 0:\n",
    "                        continue\n",
    "                    vec = np.divide(vec, norm)\n",
    "\n",
    "                    startend = list(zip(np.linspace(cand_a[i][0], cand_b[j][0], num=mid_num),\n",
    "                                        np.linspace(cand_a[i][1], cand_b[j][1], num=mid_num)))\n",
    "\n",
    "                    vec_x = np.array(\n",
    "                        [score_mid[int(round(startend[I][1])), int(round(startend[I][0])), 0]\n",
    "                         for I in range(len(startend))])\n",
    "                    vec_y = np.array(\n",
    "                        [score_mid[int(round(startend[I][1])), int(round(startend[I][0])), 1]\n",
    "                         for I in range(len(startend))])\n",
    "\n",
    "                    score_midpts = np.multiply(vec_x, vec[0]) + np.multiply(vec_y, vec[1])\n",
    "                    score_with_dist_prior = sum(score_midpts) / len(score_midpts) + min(\n",
    "                        0.5 * input_image.shape[0] / norm - 1, 0)\n",
    "                    criterion1 = len(np.nonzero(score_midpts > params['thre2'])[0]) > 0.8 * len(\n",
    "                        score_midpts)\n",
    "                    criterion2 = score_with_dist_prior > 0\n",
    "                    if criterion1 and criterion2:\n",
    "                        connection_candidate.append([i, j, score_with_dist_prior,\n",
    "                                                     score_with_dist_prior + cand_a[i][2] + cand_b[j][2]])\n",
    "\n",
    "            connection_candidate = sorted(connection_candidate, key=lambda x: x[2], reverse=True)\n",
    "            connection = np.zeros((0, 5))\n",
    "            for c in range(len(connection_candidate)):\n",
    "                i, j, s = connection_candidate[c][0:3]\n",
    "                if i not in connection[:, 3] and j not in connection[:, 4]:\n",
    "                    connection = np.vstack([connection, [cand_a[i][3], cand_b[j][3], s, i, j]])\n",
    "                    if len(connection) >= min(n_a, n_b):\n",
    "                        break\n",
    "\n",
    "            connection_all.append(connection)\n",
    "        else:\n",
    "            special_k.append(k)\n",
    "            connection_all.append([])\n",
    "\n",
    "    # last number in each row is the total parts number of that person\n",
    "    # the second last number in each row is the score of the overall configuration\n",
    "    subset = np.empty((0, 20))\n",
    "    candidate = np.array([item for sublist in all_peaks for item in sublist])\n",
    "\n",
    "    for k in range(len(util.hmapIdx)):\n",
    "        if k not in special_k:\n",
    "            part_as = connection_all[k][:, 0]\n",
    "            part_bs = connection_all[k][:, 1]\n",
    "            index_a, index_b = np.array(util.limbSeq[k]) - 1\n",
    "\n",
    "            for i in range(len(connection_all[k])):  # = 1:size(temp,1)\n",
    "                found = 0\n",
    "                subset_idx = [-1, -1]\n",
    "                for j in range(len(subset)):  # 1:size(subset,1):\n",
    "                    if subset[j][index_a] == part_as[i] or subset[j][index_b] == part_bs[i]:\n",
    "                        subset_idx[found] = j\n",
    "                        found += 1\n",
    "\n",
    "                if found == 1:\n",
    "                    j = subset_idx[0]\n",
    "                    if subset[j][index_b] != part_bs[i]:\n",
    "                        subset[j][index_b] = part_bs[i]\n",
    "                        subset[j][-1] += 1\n",
    "                        subset[j][-2] += candidate[part_bs[i].astype(int), 2] + connection_all[k][i][2]\n",
    "                elif found == 2:  # if found 2 and disjoint, merge them\n",
    "                    j1, j2 = subset_idx\n",
    "                    membership = ((subset[j1] >= 0).astype(int) + (subset[j2] >= 0).astype(int))[:-2]\n",
    "                    if len(np.nonzero(membership == 2)[0]) == 0:  # merge\n",
    "                        subset[j1][:-2] += (subset[j2][:-2] + 1)\n",
    "                        subset[j1][-2:] += subset[j2][-2:]\n",
    "                        subset[j1][-2] += connection_all[k][i][2]\n",
    "                        subset = np.delete(subset, j2, 0)\n",
    "                    else:  # as like found == 1\n",
    "                        subset[j1][index_b] = part_bs[i]\n",
    "                        subset[j1][-1] += 1\n",
    "                        subset[j1][-2] += candidate[part_bs[i].astype(int), 2] + connection_all[k][i][2]\n",
    "\n",
    "                # if find no partA in the subset, create a new subset\n",
    "                elif not found and k < 17:\n",
    "                    row = -1 * np.ones(20)\n",
    "                    row[index_a] = part_as[i]\n",
    "                    row[index_b] = part_bs[i]\n",
    "                    row[-1] = 2\n",
    "                    row[-2] = sum(candidate[connection_all[k][i, :2].astype(int), 2]) + connection_all[k][i][2]\n",
    "                    subset = np.vstack([subset, row])\n",
    "\n",
    "    # delete some rows of subset which has few parts occur\n",
    "    delete_idx = []\n",
    "    for i in range(len(subset)):\n",
    "        if subset[i][-1] < 4 or subset[i][-2] / subset[i][-1] < 0.4:\n",
    "            delete_idx.append(i)\n",
    "    subset = np.delete(subset, delete_idx, axis=0)\n",
    "    points = []\n",
    "    for peak in all_peaks:\n",
    "        try:\n",
    "            points.append((peak[0][:2]))\n",
    "        except IndexError:\n",
    "            points.append((None, None))\n",
    "    body_parts = dict(zip(COCO_BODY_PARTS, points))\n",
    "    \n",
    "    toc = time.time()\n",
    "    print(f\"Post-processing time {tic-toc}\")\n",
    "    \n",
    "    return body_parts, all_peaks, subset, candidate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running for video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import time\n",
    "from config_reader import config_reader\n",
    "\n",
    "from model.cmu_model import get_testing_model\n",
    "\n",
    "#sys.path.append(os.path.join(os.path.dirname(__file__), \"..\"))\n",
    "\n",
    "currentDT = time.localtime()\n",
    "start_datetime = time.strftime(\"-%m-%d-%H-%M-%S\", currentDT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "keras_weights_file = 'model/keras/model.h5'\n",
    "frame_rate_ratio = 5\n",
    "process_speed = 1\n",
    "ending_frame = None\n",
    "\n",
    "# Video input\n",
    "video = 'smoking2hd.mp4'\n",
    "video_path = 'videos/'\n",
    "video_file = video_path + video\n",
    "\n",
    "# Output location\n",
    "output_path = 'videos/outputs/'\n",
    "output_format = '.mp4'\n",
    "video_output = output_path + video + str(start_datetime) + output_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "# authors of original model don't use\n",
    "# vgg normalization (subtracting mean) on input images\n",
    "model = get_testing_model()\n",
    "model.load_weights(keras_weights_file)\n",
    "\n",
    "# load config\n",
    "params, model_params = config_reader()\n",
    "\n",
    "# Video reader\n",
    "cam = cv2.VideoCapture(video_file)\n",
    "input_fps = cam.get(cv2.CAP_PROP_FPS)\n",
    "ret_val, orig_image = cam.read()\n",
    "video_length = int(cam.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "if ending_frame is None:\n",
    "    ending_frame = video_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image rescaling time is 0.00342\n",
      "cnn model time is 2.07086\n",
      "Processing frame:  0\n",
      "image rescaling time is 0.00371\n",
      "cnn model time is 0.31377\n",
      "Processing frame:  5\n",
      "image rescaling time is 0.00490\n",
      "cnn model time is 0.15369\n",
      "Processing frame:  10\n",
      "image rescaling time is 0.00349\n",
      "cnn model time is 0.15525\n",
      "Processing frame:  15\n",
      "image rescaling time is 0.00373\n",
      "cnn model time is 0.15456\n",
      "Processing frame:  20\n",
      "image rescaling time is 0.00374\n",
      "cnn model time is 0.15420\n",
      "Processing frame:  25\n",
      "image rescaling time is 0.00339\n",
      "cnn model time is 0.15545\n",
      "Processing frame:  30\n",
      "image rescaling time is 0.00505\n",
      "cnn model time is 0.15429\n",
      "Processing frame:  35\n",
      "image rescaling time is 0.00371\n",
      "cnn model time is 0.15485\n",
      "Processing frame:  40\n",
      "image rescaling time is 0.00466\n",
      "cnn model time is 0.15479\n",
      "Processing frame:  45\n",
      "image rescaling time is 0.00372\n",
      "cnn model time is 0.15393\n",
      "Processing frame:  50\n",
      "image rescaling time is 0.00374\n",
      "cnn model time is 0.15383\n",
      "Processing frame:  55\n",
      "image rescaling time is 0.00341\n",
      "cnn model time is 0.15527\n",
      "Processing frame:  60\n",
      "image rescaling time is 0.00376\n",
      "cnn model time is 0.15424\n",
      "Processing frame:  65\n",
      "image rescaling time is 0.00499\n",
      "cnn model time is 0.15453\n",
      "Processing frame:  70\n",
      "image rescaling time is 0.00348\n",
      "cnn model time is 0.15499\n",
      "Processing frame:  75\n",
      "image rescaling time is 0.00375\n",
      "cnn model time is 0.15454\n",
      "Processing frame:  80\n",
      "image rescaling time is 0.00373\n",
      "cnn model time is 0.15436\n",
      "Processing frame:  85\n",
      "image rescaling time is 0.00354\n",
      "cnn model time is 0.15556\n",
      "Processing frame:  90\n",
      "image rescaling time is 0.00518\n",
      "cnn model time is 0.15444\n",
      "Processing frame:  95\n",
      "image rescaling time is 0.00371\n",
      "cnn model time is 0.15504\n",
      "Processing frame:  100\n",
      "image rescaling time is 0.00340\n",
      "cnn model time is 0.15559\n",
      "Processing frame:  105\n",
      "image rescaling time is 0.00369\n",
      "cnn model time is 0.15459\n",
      "Processing frame:  110\n",
      "image rescaling time is 0.00372\n",
      "cnn model time is 0.15406\n",
      "Processing frame:  115\n",
      "image rescaling time is 0.00342\n",
      "cnn model time is 0.15485\n",
      "Processing frame:  120\n",
      "image rescaling time is 0.00373\n",
      "cnn model time is 0.15488\n",
      "Processing frame:  125\n",
      "image rescaling time is 0.00376\n",
      "cnn model time is 0.15504\n",
      "Processing frame:  130\n",
      "image rescaling time is 0.00339\n",
      "cnn model time is 0.15569\n",
      "Processing frame:  135\n",
      "image rescaling time is 0.00371\n",
      "cnn model time is 0.15355\n",
      "Processing frame:  140\n",
      "image rescaling time is 0.00374\n",
      "cnn model time is 0.15448\n",
      "Processing frame:  145\n",
      "image rescaling time is 0.00340\n",
      "cnn model time is 0.15552\n",
      "Processing frame:  150\n",
      "image rescaling time is 0.00492\n",
      "cnn model time is 0.15444\n",
      "Processing frame:  155\n",
      "image rescaling time is 0.00372\n",
      "cnn model time is 0.15397\n",
      "Processing frame:  160\n",
      "image rescaling time is 0.00469\n",
      "cnn model time is 0.15476\n",
      "Processing frame:  165\n",
      "image rescaling time is 0.00372\n",
      "cnn model time is 0.15557\n",
      "Processing frame:  170\n",
      "image rescaling time is 0.00372\n",
      "cnn model time is 0.15411\n",
      "Processing frame:  175\n",
      "image rescaling time is 0.00346\n",
      "cnn model time is 0.15491\n",
      "Processing frame:  180\n",
      "image rescaling time is 0.00370\n",
      "cnn model time is 0.15400\n",
      "Processing frame:  185\n",
      "image rescaling time is 0.00497\n",
      "cnn model time is 0.15394\n",
      "Processing frame:  190\n",
      "image rescaling time is 0.00340\n",
      "cnn model time is 0.15569\n",
      "Processing frame:  195\n",
      "image rescaling time is 0.00370\n",
      "cnn model time is 0.15407\n",
      "Processing frame:  200\n",
      "image rescaling time is 0.00378\n",
      "cnn model time is 0.15368\n",
      "Processing frame:  205\n",
      "image rescaling time is 0.00343\n",
      "cnn model time is 0.15432\n",
      "Processing frame:  210\n",
      "image rescaling time is 0.00578\n",
      "cnn model time is 0.15437\n",
      "Processing frame:  215\n",
      "image rescaling time is 0.00375\n",
      "cnn model time is 0.15423\n",
      "Processing frame:  220\n",
      "image rescaling time is 0.00487\n",
      "cnn model time is 0.15521\n",
      "Processing frame:  225\n",
      "image rescaling time is 0.00371\n",
      "cnn model time is 0.15431\n",
      "Processing frame:  230\n",
      "image rescaling time is 0.00371\n",
      "cnn model time is 0.15551\n",
      "Processing frame:  235\n",
      "image rescaling time is 0.00337\n",
      "cnn model time is 0.15488\n",
      "Processing frame:  240\n",
      "image rescaling time is 0.00370\n",
      "cnn model time is 0.15409\n",
      "Processing frame:  245\n"
     ]
    }
   ],
   "source": [
    "scale_search = [1, .5, 1.5, 2]  # [.5, 1, 1.5, 2]\n",
    "scale_search = scale_search[0:process_speed]\n",
    "\n",
    "params['scale_search'] = scale_search\n",
    "\n",
    "output_data = []\n",
    "i = 0  # default is 0\n",
    "while(cam.isOpened()) and ret_val is True and i < ending_frame:\n",
    "    if i % frame_rate_ratio == 0:\n",
    "\n",
    "        input_image = cv2.cvtColor(orig_image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        #tic = time.time()\n",
    "\n",
    "        # generate image with body parts\n",
    "        body_parts, all_peaks, subset, candidate = extract_parts(input_image, params, model, model_params)\n",
    "        #canvas = draw(orig_image, all_peaks, subset, candidate)\n",
    "\n",
    "        print('Processing frame: ', i)\n",
    "#         toc = time.time()\n",
    "#         print('processing time is %.5f' % (toc - tic))\n",
    "\n",
    "        #out.write(canvas)\n",
    "        \n",
    "        # create dictionary for each frame\n",
    "        frame_dict = {'frame_id': i, 'body_parts': body_parts, 'all_peaks': all_peaks, 'subset': subset, 'candidate': candidate}\n",
    "        output_data.append(frame_dict)\n",
    "    \n",
    "    ret_val, orig_image = cam.read()\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "with open('videos/video_data/smokin2mp4.pkl', 'wb') as file:\n",
    "    pickle.dump(output_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'frame_id': 5,\n",
       " 'body_parts': {'nose': (234, 87),\n",
       "  'neck': (170, 99),\n",
       "  'right_shoulder': (230, 96),\n",
       "  ' right_elbow': (227, 114),\n",
       "  'right_wrist': (177, 121),\n",
       "  'left_shoulder': (178, 98),\n",
       "  'left_elbow': (251, 124),\n",
       "  'left_wrist': (244, 142),\n",
       "  'right_hip': (169, 134),\n",
       "  'right_knee': (224, 155),\n",
       "  'right_ankle': (223, 175),\n",
       "  'left_hip': (179, 132),\n",
       "  'left_knee': (177, 155),\n",
       "  'left_ankle': (173, 174),\n",
       "  'right_eye': (233, 84),\n",
       "  'left_eye': (237, 85),\n",
       "  'right_ear': (175, 90),\n",
       "  'left_ear': (244, 85)},\n",
       " 'all_peaks': [[(234, 87, 0.8884656429290771, 0),\n",
       "   (182, 95, 0.676986575126648, 1)],\n",
       "  [(170, 99, 0.7536784410476685, 2),\n",
       "   (241, 100, 0.8877450823783875, 3),\n",
       "   (195, 119, 0.8514382243156433, 4)],\n",
       "  [(230, 96, 0.8524492979049683, 5),\n",
       "   (164, 101, 0.8598827123641968, 6),\n",
       "   (209, 124, 0.7947495579719543, 7)],\n",
       "  [(227, 114, 0.6775968670845032, 8),\n",
       "   (159, 121, 0.922542154788971, 9),\n",
       "   (217, 152, 0.8079068064689636, 10)],\n",
       "  [(177, 121, 0.5875738859176636, 11),\n",
       "   (225, 129, 0.5795606374740601, 12),\n",
       "   (234, 153, 0.6764605045318604, 13)],\n",
       "  [(178, 98, 0.5508155822753906, 14),\n",
       "   (251, 102, 0.8536717295646667, 15),\n",
       "   (182, 113, 0.7998271584510803, 16)],\n",
       "  [(251, 124, 0.8128988742828369, 17)],\n",
       "  [(244, 142, 0.7223041653633118, 18)],\n",
       "  [(169, 134, 0.8827341198921204, 19),\n",
       "   (228, 134, 0.7208351492881775, 20),\n",
       "   (204, 168, 0.6841245293617249, 21)],\n",
       "  [(224, 155, 0.7000874876976013, 22),\n",
       "   (170, 157, 0.9047110676765442, 23),\n",
       "   (202, 196, 0.7802679538726807, 24)],\n",
       "  [(223, 175, 0.8581738471984863, 25),\n",
       "   (165, 180, 0.9109554290771484, 26),\n",
       "   (197, 221, 0.43578237295150757, 27)],\n",
       "  [(179, 132, 0.6860805749893188, 28),\n",
       "   (241, 138, 0.7190679311752319, 29),\n",
       "   (189, 163, 0.6765323877334595, 30)],\n",
       "  [(177, 155, 0.7407761812210083, 31),\n",
       "   (239, 162, 0.7417725920677185, 32),\n",
       "   (187, 192, 0.7684381604194641, 33)],\n",
       "  [(173, 174, 0.8676115274429321, 34),\n",
       "   (236, 184, 0.8603151440620422, 35),\n",
       "   (184, 215, 0.5055895447731018, 36)],\n",
       "  [(233, 84, 0.8225712180137634, 37), (181, 92, 0.7100087404251099, 38)],\n",
       "  [(237, 85, 0.9514500498771667, 39), (185, 93, 0.1937243491411209, 40)],\n",
       "  [(175, 90, 0.680107593536377, 41), (207, 97, 0.8346052169799805, 42)],\n",
       "  [(244, 85, 0.8491314053535461, 43), (192, 96, 0.3255792558193207, 44)]],\n",
       " 'subset': array([[ 0.        ,  3.        ,  5.        ,  8.        , 12.        ,\n",
       "         15.        , 17.        , 18.        , 20.        , 22.        ,\n",
       "         25.        , 29.        , 32.        , 35.        , 37.        ,\n",
       "         39.        , -1.        , 43.        , 27.80140412, 17.        ],\n",
       "        [-1.        ,  4.        ,  7.        , 10.        , 13.        ,\n",
       "         16.        , -1.        , -1.        , 21.        , 24.        ,\n",
       "         27.        , 30.        , 33.        , 36.        , -1.        ,\n",
       "         -1.        , 42.        , 44.        , 19.06139981, 13.        ],\n",
       "        [ 1.        ,  2.        ,  6.        ,  9.        , 11.        ,\n",
       "         14.        , -1.        , -1.        , 19.        , 23.        ,\n",
       "         26.        , 28.        , 31.        , 34.        , 38.        ,\n",
       "         40.        , 41.        , -1.        , 22.42986475, 15.        ]]),\n",
       " 'candidate': array([[2.34000000e+02, 8.70000000e+01, 8.88465643e-01, 0.00000000e+00],\n",
       "        [1.82000000e+02, 9.50000000e+01, 6.76986575e-01, 1.00000000e+00],\n",
       "        [1.70000000e+02, 9.90000000e+01, 7.53678441e-01, 2.00000000e+00],\n",
       "        [2.41000000e+02, 1.00000000e+02, 8.87745082e-01, 3.00000000e+00],\n",
       "        [1.95000000e+02, 1.19000000e+02, 8.51438224e-01, 4.00000000e+00],\n",
       "        [2.30000000e+02, 9.60000000e+01, 8.52449298e-01, 5.00000000e+00],\n",
       "        [1.64000000e+02, 1.01000000e+02, 8.59882712e-01, 6.00000000e+00],\n",
       "        [2.09000000e+02, 1.24000000e+02, 7.94749558e-01, 7.00000000e+00],\n",
       "        [2.27000000e+02, 1.14000000e+02, 6.77596867e-01, 8.00000000e+00],\n",
       "        [1.59000000e+02, 1.21000000e+02, 9.22542155e-01, 9.00000000e+00],\n",
       "        [2.17000000e+02, 1.52000000e+02, 8.07906806e-01, 1.00000000e+01],\n",
       "        [1.77000000e+02, 1.21000000e+02, 5.87573886e-01, 1.10000000e+01],\n",
       "        [2.25000000e+02, 1.29000000e+02, 5.79560637e-01, 1.20000000e+01],\n",
       "        [2.34000000e+02, 1.53000000e+02, 6.76460505e-01, 1.30000000e+01],\n",
       "        [1.78000000e+02, 9.80000000e+01, 5.50815582e-01, 1.40000000e+01],\n",
       "        [2.51000000e+02, 1.02000000e+02, 8.53671730e-01, 1.50000000e+01],\n",
       "        [1.82000000e+02, 1.13000000e+02, 7.99827158e-01, 1.60000000e+01],\n",
       "        [2.51000000e+02, 1.24000000e+02, 8.12898874e-01, 1.70000000e+01],\n",
       "        [2.44000000e+02, 1.42000000e+02, 7.22304165e-01, 1.80000000e+01],\n",
       "        [1.69000000e+02, 1.34000000e+02, 8.82734120e-01, 1.90000000e+01],\n",
       "        [2.28000000e+02, 1.34000000e+02, 7.20835149e-01, 2.00000000e+01],\n",
       "        [2.04000000e+02, 1.68000000e+02, 6.84124529e-01, 2.10000000e+01],\n",
       "        [2.24000000e+02, 1.55000000e+02, 7.00087488e-01, 2.20000000e+01],\n",
       "        [1.70000000e+02, 1.57000000e+02, 9.04711068e-01, 2.30000000e+01],\n",
       "        [2.02000000e+02, 1.96000000e+02, 7.80267954e-01, 2.40000000e+01],\n",
       "        [2.23000000e+02, 1.75000000e+02, 8.58173847e-01, 2.50000000e+01],\n",
       "        [1.65000000e+02, 1.80000000e+02, 9.10955429e-01, 2.60000000e+01],\n",
       "        [1.97000000e+02, 2.21000000e+02, 4.35782373e-01, 2.70000000e+01],\n",
       "        [1.79000000e+02, 1.32000000e+02, 6.86080575e-01, 2.80000000e+01],\n",
       "        [2.41000000e+02, 1.38000000e+02, 7.19067931e-01, 2.90000000e+01],\n",
       "        [1.89000000e+02, 1.63000000e+02, 6.76532388e-01, 3.00000000e+01],\n",
       "        [1.77000000e+02, 1.55000000e+02, 7.40776181e-01, 3.10000000e+01],\n",
       "        [2.39000000e+02, 1.62000000e+02, 7.41772592e-01, 3.20000000e+01],\n",
       "        [1.87000000e+02, 1.92000000e+02, 7.68438160e-01, 3.30000000e+01],\n",
       "        [1.73000000e+02, 1.74000000e+02, 8.67611527e-01, 3.40000000e+01],\n",
       "        [2.36000000e+02, 1.84000000e+02, 8.60315144e-01, 3.50000000e+01],\n",
       "        [1.84000000e+02, 2.15000000e+02, 5.05589545e-01, 3.60000000e+01],\n",
       "        [2.33000000e+02, 8.40000000e+01, 8.22571218e-01, 3.70000000e+01],\n",
       "        [1.81000000e+02, 9.20000000e+01, 7.10008740e-01, 3.80000000e+01],\n",
       "        [2.37000000e+02, 8.50000000e+01, 9.51450050e-01, 3.90000000e+01],\n",
       "        [1.85000000e+02, 9.30000000e+01, 1.93724349e-01, 4.00000000e+01],\n",
       "        [1.75000000e+02, 9.00000000e+01, 6.80107594e-01, 4.10000000e+01],\n",
       "        [2.07000000e+02, 9.70000000e+01, 8.34605217e-01, 4.20000000e+01],\n",
       "        [2.44000000e+02, 8.50000000e+01, 8.49131405e-01, 4.30000000e+01],\n",
       "        [1.92000000e+02, 9.60000000e+01, 3.25579256e-01, 4.40000000e+01]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
